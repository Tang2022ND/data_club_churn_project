---
title: "Telco Churn Prediction"
output: html_document
author: "Notre Dame Data Club"
---


##  **1. Exploratory Data Analysis** 
### **1.1 Load Packages**
```{r, results = FALSE, message=FALSE, warning=FALSE}
library(doParallel) #multicore processing
library(glmnet) #lasso
library(ggplot2) #ploting
library(forecast) 
library(caret) #ml package
library(dplyr) 
library(OptimalCutpoints)  #best cut point
library(xgboost) #xgboost
library(splitstackshape) #data partition
library(naniar)#find missing value
library(DMwR)#SMOTE
library(xgboostExplainer) # Load XGboost Explainer
library(pROC) # Load proc
library(randomForest)
library(fastDummies)
```



### **1.2Load the data**

```{r}
load("churn_data.rda") #Load the data 
```
**CustomerID**: A unique ID that identifies each customer.

**Gender**: The customer’s gender: Male, Female

**Age**: The customer’s current age, in years, at the time the fiscal quarter ended.

**Senior Citizen**: Indicates if the customer is 65 or older: Yes, No

**Dependents**: Indicates if the customer lives with any dependents: Yes, No. Dependents could be children, parents, grandparents, etc.

**City**: The city of the customer’s primary residence.

**Monthly Charge**: Indicates the customer’s current total monthly charge for all their services from the company.

**Number of Referrals**: Indicates the number of referrals to date that the customer has made.

**Population**: A current population estimate for the entire Zip Code area.

**Tenure in Months**: Indicates the total amount of months that the customer has been with the company by the end of the quarter specified above.

**Contract**: Indicates the customer’s current contract type: Month-to-Month, One Year, Two Year.

**Churn Value**: 1 = the customer left the company this quarter. 0 = the customer remained with the company. Directly related to Churn Label.

**CLTV**: Customer Lifetime Value. A predicted CLTV is calculated using corporate formulas and existing data. The higher the value, the more valuable the customer. High value customers should be monitored for churn.

**Satisfaction Score**: A customer’s overall satisfaction rating of the company from 1 (Very Unsatisfied) to 5 (Very Satisfied).

**Churn Score**: A value from 0-100 that is calculated using the predictive tool IBM SPSS Modeler. The model incorporates multiple factors known to cause churn. The higher the score, the more likely the customer will churn.


### **1.3Data information and cheat variables**

```{r, echo=FALSE,fig.width=12, fig.height=8}
dim(churn_data)

churn_data$Churn.Value <- as.factor(churn_data$Churn.Value)
ggplot(data = churn_data,aes(x = Churn.Value,fill = Churn.Value))+
  geom_bar()+theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())

ggplot(data = churn_data,aes(x = Churn.Score,fill = Churn.Value))+
  geom_bar()+theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())

ggplot(data = churn_data,aes(x = Satisfaction.Score,fill = Churn.Value))+
  geom_bar()+theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```


### **1.4Data pre-processing**

```{r,warning=FALSE}

churn_data$Zip.Code <- as.factor(churn_data$Zip.Code) #zip code is should be a factor, but we are going to use them anyway....
total_data <- cbind.data.frame(churn_value = churn_data$Churn.Value,churn_data[,-c(1,2,10,11,13,14,17,18,19,20,21,22,24,25,26)]) # move the churn.value to the first row
indx <- which(unlist(summarise_each(total_data, funs(class)) =='character')) #select the character columns
for (i in indx){
  total_data[,i] <- gsub(" ", "_",total_data[,i])
  total_data[,i] <- gsub("-", "_",total_data[,i])#need to replace the space and hyphen to underscore, it will smooth the later scaling process
}
```


### **RandomForest Important Variables**

```{r, echo=FALSE,fig.width=12, fig.height=8}
rf <- randomForest(churn_value~., total_data[,-c(10,11)])
varImpPlot(rf, type =2, n.var = 10)
```


### **Consumer Distribution**

```{r, echo=FALSE, message=FALSE, warning=FALSE,fig.width=12, fig.height=8}
library(ggmap)

register_google("AIzaSyAVJQUd1mGICFac5zKE_r055727U5MJO9s")
CAmap <- get_map(location ='california',zoom = 6, maptype = "roadmap", color = "bw")
ggmap(CAmap, base_layer = ggplot(aes(x = Longitude, y= Latitude), data = total_data)) + 
  geom_point(data = total_data, aes(color = churn_value, alpha = 0.3)) 

```

### **Contract**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Contract, fill = churn_value))+
  geom_bar()+ 
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```


### **Monthly Charge**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Monthly.Charge, fill = churn_value))+
  geom_density(alpha = 0.5)+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Tenure in Months**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Tenure.in.Months, fill = churn_value))+
  geom_density(alpha = 0.5)+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Number of Referrals**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Number.of.Referrals, fill = churn_value))+
  geom_bar()+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **City**

```{r,echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = City, fill = churn_value))+
  geom_bar()+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Top 7 Cities**

```{r, echo=FALSE, warning=FALSE,fig.width=12, fig.height=8}
plot_city_dat <- data.frame(total_user = summary(factor(total_data$City)))
ggplot(data = total_data[total_data$City == rownames(plot_city_dat)[1:7],], aes(x = City, fill = churn_value))+
  geom_bar()+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Age**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Age, fill = churn_value))+
  geom_bar()+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Senior-City**

```{r, echo=FALSE, warning=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data[total_data$City == rownames(plot_city_dat)[1:3],], aes(x = City, fill = churn_value))+
  geom_bar()+
  facet_grid(~Senior.Citizen)+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Population Density**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Population, fill = churn_value))+
  geom_density(alpha = 0.5)+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```

### **Senior-Contract**

```{r, echo=FALSE,fig.width=12, fig.height=8}
ggplot(data = total_data, aes(x = Contract, fill = churn_value))+
  geom_bar()+
  facet_grid(~Senior.Citizen)+
  theme_bw()+
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
```











##  **2. Machine learning modeling** 
### **2.1 Data Scaling and Dummy Variables**

```{r}
total_data <- total_data %>% select(-Longitude,-Latitude)
scaledata <- dummy_cols(total_data[,-1],remove_selected_columns = T)
scaledata <- scale(scaledata)
scaledata <- cbind.data.frame(churn_value= total_data$churn_value,scaledata)
dim(scaledata)
```





### **2.2 Lasso Regression**
#### **2.2.1 Find the Best lambda for the data set**

```{r}
set.seed(1)
temp_lasso <- stratified(scaledata, group = "churn_value", size = 0.8,bothSets = T)
lasso_train <- temp_lasso[[1]]
lasso_test <- data.matrix(temp_lasso[[2]])
lasso_test[,1] <-lasso_test[,1]-1

doParallel::registerDoParallel(cores = 6)
x_vars <- as.matrix(lasso_train[,-1])
lambda_seq <- 10^seq(4, -4, by = -.1)
cv.lasso <- cv.glmnet(x = x_vars, 
                      y = lasso_train$churn_value, 
                      alpha = 1, 
                      family = "binomial", 
                      lambda = lambda_seq, 
                      parallel = T,
                      nfolds = 10)
best_lam <- cv.lasso$lambda.1se 

lambda_seq <- seq(best_lam-0.004,best_lam+0.005,0.0001)# reduce the testing range

cv.lasso <- cv.glmnet(x = x_vars, 
                      y = lasso_train$churn_value, 
                      alpha = 1, 
                      family = "binomial", 
                      lambda = lambda_seq,
                      parallel = T,
                      nfolds = 10)
best_lam <- cv.lasso$lambda.1se
best_lam 

best_lasso <- glmnet(x = x_vars,
                     y = lasso_train$churn_value,
                     alpha = 1,
                     family = "binomial",
                     lambda = best_lam)


lasso_coef <- as.data.frame(as.matrix(coef(best_lasso))) %>% filter(s0 != 0)
lasso_coef_list <- c("churn_value",row.names(lasso_coef)[-1])

```



#### **2.2.2 Fitting the lasso Regression model**

```{r}

x_vars <- lasso_train[,-1]
best_lasso1 <- glmnet(x = x_vars,
                     y = as.factor(lasso_train$churn_value),
                     alpha = 1,
                     family = "binomial",
                     type.measure="class",
                     lambda = best_lam)
 
```



#### **2.2.3 Predicting and find the best Cutoff Point**

```{r}

lasso_pred <- predict(best_lasso1, lasso_test[,-1], type = "response")
df_pred <- cbind.data.frame(response = lasso_test[,1],prediction = lasso_pred[,1])
oc<- optimal.cutpoints(X = "prediction",
                       status = "response",
                       tag.healthy = 0,
                       data = df_pred,
                       methods = "MaxEfficiency")

best_cut_off <- oc$MaxEfficiency$Global$optimal.cutoff$cutoff[1]
best_cut_off
```



#### **2.2.4 Lasso Regression Confusion Matrix**

```{r}
lasso_result <- ifelse(lasso_pred > best_cut_off, 1, 0)
t <- table(prediction = lasso_result[,1],response = lasso_test[,1])
confusionMatrix(t, positive = "1")
```





### **2.3 Xgboost**
#### **2.3.1 Xgboost data preparation**

```{r}
xgb_total <- dummy_columns(total_data[,-1],remove_selected_columns = T)
xgb_total <- cbind.data.frame(churn_value= total_data$churn_value,xgb_total)
xgb_total <- xgb_total[,lasso_coef_list]


set.seed(1)
temp <- stratified(as.data.frame(xgb_total), group = "churn_value", size = .8, bothSets = T)
xgb_prep <- data.matrix(temp[[1]])
xgb_prep[,1] <- xgb_prep[,1]-1
xgb_prep1 <- data.matrix(temp[[2]])
xgb_prep1[,1] <- xgb_prep1[,1]-1

xgb_train <- xgb.DMatrix(data = xgb_prep[,-1], label = xgb_prep[,1] )
xgb_test <- xgb.DMatrix(data = xgb_prep1[,-1], label = xgb_prep1[,1] )

xgb_prep <- data.frame(temp[[1]])
xgb_prep1 <- data.frame(temp[[2]])
```



#### **2.3.2 Fitting the Xgboost Model(w/o tuning)**

```{r}
set.seed(1)
bst <- xgboost(data = xgb_train, # Set training data
               eta = 0.1, # Set learning rate
               nrounds = 2000, # Set number of rounds
               early_stopping_rounds = 50, # Set number of rounds to stop at 
               verbose = 0, # 1 - Prints out fit
               nthread = 6, # Set number of parallel threads
               
               objective = "binary:logistic", # Set objective
               eval_metric = "auc",
               eval_metric = "error") 
xgb_pred <- predict(bst, xgb_test)
pred_dat <- cbind.data.frame(prediction = xgb_pred , response = xgb_prep1$churn_value)


oc<- optimal.cutpoints(X = "prediction",
                       status = "response",
                       tag.healthy = 0,
                       data = pred_dat,
                       methods = "MaxEfficiency")

best_cut_off <- oc$MaxEfficiency$Global$optimal.cutoff$cutoff
result <- ifelse(xgb_pred > best_cut_off, 1, 0)
t <- table(prediction = result,response = xgb_prep1$churn_value)
confusionMatrix(t, positive = "1")
```


#### **2.3.3 Xgboost Model(w/o tuning) vs Lasso Regression**


```{r,  echo=FALSE, message=FALSE, warning=FALSE}
xgb_roc <-  roc(xgb_prep1$churn_value,xgb_pred)
lasso_roc <-  roc(lasso_test[,1],lasso_pred)
```
```{r, warning= FALSE,results = FALSE}

plot.roc(xgb_roc, print.auc = TRUE, col = "red", print.auc.col = "red")
plot.roc(lasso_roc, print.auc = TRUE, print.auc.x = 0, print.auc.y = 0.6, col ="blue", print.auc.col = "blue", add = TRUE)
```





### **2.4 Xgboost Tuning**
#### **2.4.1 Xgboost tuning preparation**

```{r}
grid_search <- expand.grid(
  max_depth_list = c(2,3,4,5,6),
  min_child_weight = c(0,1,2,4,5),
  gamma_list = c(0.4),
  subsample = c(1), # Create vector of subsample values
  colsample_by_tree = c(0.7) # Create vector of col sample
)
auc_vec <- error_vec <- rep(NA, nrow(grid_search)) 
```



#### **2.4.2 Xgboost Gridsearch Cross Validation**

```{r}
for (i in 1:nrow(grid_search)){
  set.seed(1)
  bst.tune <- xgb.cv(data = xgb_train,
                     eta = 0.1, # Set learning rate
                     nrounds = 1000, # Set number of rounds
                     early_stopping_rounds = 100, # Set number of rounds to stop at 
                     verbose = 0, # 1 - Prints out fit
                     nthread = 6, # Set number of parallel threads

                     max.depth = grid_search$max_depth_list[i],
                     min_child_weight = grid_search$min_child_weight[i],
                     gamma = grid_search$gamma_list[i],
                     subsample = grid_search$subsample[i],
                     colsample_by_tree = grid_search$colsample_by_tree[i],
                     
                     nfold = 5,
                     objective = "binary:logistic", # Set objective
                     eval_metric = "auc",
                     eval_metric = "error")
  auc_vec[i] <- bst.tune$evaluation_log$test_auc_mean[bst.tune$best_ntreelimit]
  error_vec[i] <- bst.tune$evaluation_log$test_error_mean[bst.tune$best_ntreelimit]
}
res_db <- cbind.data.frame(grid_search, auc = auc_vec, error = error_vec)
res_db$max_depth_list <- as.factor(res_db$max_depth_list)
res_db$min_child_weight <- as.factor(res_db$min_child_weight)
```


#### **2.4.3 Gridsearch Visualization**


```{r}

ggplot(res_db, aes(x = max_depth_list, y = min_child_weight, fill = auc))+ geom_tile()+ scale_fill_gradient2(low = "blue", "AUC",high = "red", midpoint =mean(res_db$auc))
ggplot(res_db, aes(x = max_depth_list, y = min_child_weight, fill = error))+ geom_tile()+scale_fill_gradient2(low = "blue", "Error",high = "red", midpoint =mean(res_db$error))

```



#### **2.4.4 Xgboost ETA tuning**

```{r}
eta_tuning <- function(eta_val){
set.seed(1)
bst_eta <- xgb.cv(data = xgb_train, # Set training data
                     nfold = 5, # Use 5 fold cross-validation
                     eta = eta_val, # Set learning rate
                     max.depth = 3,
                     min_child_weight = 0,
                     gamma = 0.4,
                     subsample = 1, # Set proportion of training data to use in tree
                     colsample_bytree = 0.7, # Set number of variables to use in each tree
                     nrounds = 20000, # Set number of rounds
                     early_stopping_rounds = 1000, # Set number of rounds to stop at if there is no improvement
                     verbose = 0, # 1 - Prints out fit
                     nthread = 6, # Set number of parallel threads
                     objective = "binary:logistic", # Set objective
                     eval_metric = "auc",
                     eval_metric = "error") # Set evaluation metric to use
}

eta_0.005 <- eta_tuning(0.005)
eta_0.01 <- eta_tuning(0.01)
eta_0.05 <- eta_tuning(0.05)
eta_0.1 <- eta_tuning(0.1)
eta_0.3 <- eta_tuning(0.3)

pd1 <- cbind.data.frame(eta_0.005$evaluation_log[,c("iter", "test_error_mean")], rep(0.005, nrow(eta_0.005$evaluation_log)))
names(pd1)[c(1,2,3)] <- c("iter","error","eta")
pd2 <- cbind.data.frame(eta_0.01$evaluation_log[,c("iter", "test_error_mean")], rep(0.01, nrow(eta_0.01$evaluation_log)))
names(pd2)[c(1,2,3)] <- c("iter","error","eta")
pd3 <- cbind.data.frame(eta_0.05$evaluation_log[,c("iter", "test_error_mean")], rep(0.05, nrow(eta_0.05$evaluation_log)))
names(pd3)[c(1,2,3)] <- c("iter","error","eta")
pd4 <- cbind.data.frame(eta_0.1$evaluation_log[,c("iter", "test_error_mean")], rep(0.1, nrow(eta_0.1$evaluation_log)))
names(pd4)[c(1,2,3)] <- c("iter","error","eta")
pd5 <- cbind.data.frame(eta_0.3$evaluation_log[,c("iter", "test_error_mean")], rep(0.3, nrow(eta_0.3$evaluation_log)))
names(pd5)[c(1,2,3)] <- c("iter","error","eta")
```


#### **2.4.5 Xgboost ETA Visualization**


```{r,fig.width=12, fig.height=8}
plot_data <- rbind.data.frame(pd1, pd2, pd3, pd4, pd5)
plot_data$eta <- as.factor(plot_data$eta)
ggplot(plot_data, aes(x = iter, y = error, color = eta))+
  geom_smooth(method = 'gam', formula= y ~ s(x, bs = "cs"), alpha = 0.5)+
  theme_bw()
```



#### **2.4.6 Fitting the final Xgboost Model(w/ tuning)**

```{r}
set.seed(1)
bst <- xgboost(data = xgb_train, # Set training data
                     eta = 0.1, # Set learning rate
                     max.depth = 3,
                     min_child_weight = 0,
                     gamma = 0.4,
                     subsample = 1, # Set proportion of training data to use in tree
                     colsample_bytree = 0.7, # Set number of variables to use in each tree
                     
                     nrounds = 480, # Set number of rounds
                     
                     verbose = 1, # 1 - Prints out fit
                     nthread = 6, # Set number of parallel threads
                     print_every_n = 100, # Prints out result every 20th iteration
                     
                     objective = "binary:logistic", # Set objective
                     eval_metric = "auc",
                     eval_metric = "error") # Set evaluation metric to use
xgb_pred <- predict(bst, xgb_test)
pred_dat <- cbind.data.frame(prediction = xgb_pred , response = xgb_prep1$churn_value)


oc<- optimal.cutpoints(X = "prediction",
                       status = "response",
                       tag.healthy = 0,
                       data = pred_dat,
                       methods = "MaxEfficiency")

best_cut_off <- oc$MaxEfficiency$Global$optimal.cutoff$cutoff
bst_xgb_result <- ifelse(xgb_pred > best_cut_off, 1, 0)
t <- table(prediction = bst_xgb_result,response = xgb_prep1$churn_value)
confusionMatrix(t, positive = "1")

```


#### **2.4.7 Xgboost Variable importance**


```{r,echo=FALSE}
imp_mat <- xgb.importance(model = bst)
xgb.plot.importance(imp_mat, top_n = 10)
```


#### **2.4.8 Xgboost Model(w/ tuning) vs Lasso Regression**


```{r,  echo=FALSE, message=FALSE, warning=FALSE}
xgb_roc <-  roc(xgb_prep1$churn_value,xgb_pred)
lasso_roc <-  roc(lasso_test[,1],lasso_pred)
plot.roc(xgb_roc, print.auc = TRUE, col = "red", print.auc.col = "red")
plot.roc(lasso_roc, print.auc = TRUE, print.auc.x = 0, print.auc.y = 0.6, col ="blue", print.auc.col = "blue", add = TRUE)
```





### **2.5 other Machine learning models**
#### **2.5.1 Data Processing(Normalization) for other Machine learning models**

```{r}
set.seed(1)
normalized_dat <- xgb_total[,lasso_coef_list][,-1]
x_mean <- apply(normalized_dat, 2, mean)
x_sd <- apply(normalized_dat, 2, sd)
normalized_dat <- scale(normalized_dat, center = x_mean, scale = x_sd) #normalize the training data
normalized_dat <- cbind.data.frame(churn_value = xgb_total$churn_value, normalized_dat)

temp_total <- stratified(normalized_dat, group = "churn_value", size = 0.8,bothSets = T)#seed 1 will make sure we always get the same partittion
train_data <- temp_total[[1]] 
test_data <- temp_total[[2]]
```



#### **2.5.2 Fitting the Model(Logistic Regession, Generalized additive model, NN)**

```{r}
lm_full <- glm(churn_value ~.,train_data, family = "binomial")
library(gam)
gam_1 <- gam(churn_value ~ s(Number.of.Referrals) + s(Tenure.in.Months) + s(Monthly.Charge) + 
    s(Population) + Senior.Citizen_No + Senior.Citizen_Yes + Dependents_No + 
    Dependents_Yes + City_Acampo + City_Bakersfield + City_Camp_Nelson + 
    City_Daly_City + City_Fallbrook + City_Grizzly_Flats + City_Jackson + 
    City_La_Puente + City_Pearblossom + City_Riverbank + City_San_Diego + 
    City_San_Dimas + City_Smith_River + City_Temecula + City_Thousand_Palms + 
    City_Travis_Afb + City_Twain + City_Upland + City_Winterhaven + 
    Referred.a.Friend_No + Referred.a.Friend_Yes + Offer_Offer_D + 
    Offer_Offer_E + Internet.Service_No + Internet.Type_Fiber_Optic + 
    Internet.Type_None + Online.Security_No + Online.Security_Yes + 
    Premium.Tech.Support_No + Premium.Tech.Support_Yes + Streaming.TV_No + 
    Streaming.TV_Yes + Streaming.Movies_No + Streaming.Movies_Yes + 
    Streaming.Music_No + Streaming.Music_Yes + Contract_Month_to_Month + 
    Contract_Two_Year + Paperless.Billing_No + Paperless.Billing_Yes + 
    Payment.Method_Credit_Card + Payment.Method_Mailed_Check, train_data, family = "binomial")
set.seed(1)
nn1 <- neuralnet::neuralnet(churn_value == 1~.,train_data, linear.output = F, hidden = c(4))
```



#### **2.5.3 Prediction and confusion Matrix**

```{r, warning=FALSE}
lm_full_pred <- predict(lm_full, test_data, type = "response")
gam_1_pred <- predict(gam_1, test_data, type = "response")
nn1_pred <- predict(nn1, test_data)
confusionMatrix(factor(ifelse(gam_1_pred>0.5, '1', '0')), test_data$churn_value, positive = '1')
confusionMatrix(factor(ifelse(lm_full_pred>0.5, '1', '0')), test_data$churn_value, positive = '1')
confusionMatrix(factor(ifelse(nn1_pred>0.5, '1', '0')), test_data$churn_value, positive = '1')
```


#### **2.5.4 ROC cruve and Lift Chart For all ML models**


```{r, echo=FALSE, message=FALSE, warning=FALSE,fig.width=12, fig.height=8}

lift_chart <- lift(xgb_prep1$churn_value~xgb_pred+lasso_pred+gam_1_pred+lm_full_pred+nn1_pred, class='1', cuts=200)
xyplot(lift_chart, auto.key=list(columns=5), main='Lift Chart')

lm_roc <- roc(test_data$churn_value, lm_full_pred)
gam_roc <- roc(test_data$churn_value, gam_1_pred)
nn_roc <- roc(test_data$churn_value, nn1_pred)

plot.roc(xgb_roc, print.auc = TRUE, col = "red",print.auc.x = 0, print.auc.y = 0.5, print.auc.col = "red")
plot.roc(lasso_roc, print.auc = TRUE, print.auc.x = 0, print.auc.y = 0.6, col ="blue", print.auc.col = "blue", add = TRUE)
plot.roc(lm_roc, print.auc = TRUE, print.auc.x = 0, print.auc.y = 0.7, col ="dark green", print.auc.col = "dark green",add = TRUE)
plot.roc(gam_roc, print.auc = TRUE, print.auc.x = 0, print.auc.y = 0.8, col ="orange", print.auc.col = "orange", add = TRUE)
plot.roc(nn_roc, print.auc = TRUE, print.auc.x = 0, print.auc.y = 0.9, col ="light blue", print.auc.col = "light blue", add = TRUE)


```






## **3. Implications for business decision making**
#### **3.1 Retention cost saving modeling**

```{r}
set.seed(1)
temp1 <- stratified(total_data, group = "churn_value", size = 0.8,bothSets = T)
test_cltv <- temp1[[2]]$CLTV

model_result <- function(x,Retention_rate, marketing_cost) {
  tuning <- seq(0, .7, 0.02) 
  accuracy_table <- matrix(0,ncol = 6,
                           nrow = length(tuning),
                           dimnames = list(tuning, c("Accuracy","Precision","Recall(Churned)","Specificity(Stayed)","F1_score","Potential_Profit")))
  
  for (i in tuning) {
    Accuracy <- length(x[(x < i & test_data$churn_value == 0)|(x > i & test_data$churn_value == 1)])/length(x)
    Precision <- length(x[x > i & test_data$churn_value == 1])/length(x[x > i])
    Recall <- length(x[x > i & test_data$churn_value == 1])/length(x[test_data$churn_value == 1])
    Specificity <- length(x[x < i & test_data$churn_value == 0])/length(x[test_data$churn_value == 0])
    F1_score <-  2 * (Recall*Precision) / (Recall + Precision)
    Potential_Profit <- sum(test_cltv[x > i & test_data$churn_value == 1])*Retention_rate-length(x[x > i])*marketing_cost
    accuracy_table[rownames(accuracy_table) == i,
                   1] <- Accuracy
    accuracy_table[rownames(accuracy_table) == i,
                   2] <- Precision
    accuracy_table[rownames(accuracy_table) == i,
                   3] <- Recall
    accuracy_table[rownames(accuracy_table) == i,
                   4] <- Specificity
    accuracy_table[rownames(accuracy_table) == i,
                   5] <- F1_score
    accuracy_table[rownames(accuracy_table) == i,
                   6] <- Potential_Profit
  }
  accuracy_table
}
business_model_result <- model_result(xgb_pred, 0.15, 100)
```



#### **3.2 Cost Saving Plot**


```{r, recho=FALSE, message=FALSE, warning=FALSE,fig.width=14, fig.height=9}
business_model_result <- cbind.data.frame(cut_point = row.names(business_model_result),business_model_result)

ggplot(data = business_model_result, aes(x = cut_point, y = Potential_Profit, color = Potential_Profit))+
  geom_point()+
  theme_bw() +
  theme(panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())

```



